{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\Yv}{\\mathbf{Y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\gv}{\\mathbf{g}}\n",
    "\\newcommand{\\Hv}{\\mathbf{H}}\n",
    "\\newcommand{\\dv}{\\mathbf{d}}\n",
    "\\newcommand{\\Vv}{\\mathbf{V}}\n",
    "\\newcommand{\\vv}{\\mathbf{v}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\Zv}{\\mathbf{Z}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2 Adam vs SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abigail Rictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display as ipd  # for display and clear_output\n",
    "import time  # for sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a long vector of all of the weights in both layers.  Then we can define the weight matrix for each layer as views into this vector.  This allows us to take steps down the gradient of the error function by incrementing the whole weight vector.\n",
    "\n",
    "Spend a little time understanding the difference between numpy views and copies.  [Here is a good tutorial](http://www.jessicayung.com/numpy-views-vs-copies-avoiding-costly-mistakes/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights(shapes):\n",
    "    '''make_weights(shape): weights is list of pairs of (n_inputs, n_units) for each layer.\n",
    "    n_inputs includes the constant 1 input.\n",
    "    Returns weight vector w of all weights, and list of matrix views into w for each layer'''\n",
    "    # Make list of number of weights in each layer\n",
    "    n_weights_each_matrix = [sh[0] * sh[1] for sh in shapes]\n",
    "    # Total number of weights\n",
    "    n_weights = sum(n_weights_each_matrix)\n",
    "    # Allocate weight vector with component for each weight\n",
    "    w = np.zeros(n_weights)\n",
    "    # List Ws will be list of weight matrix views into w for each layer\n",
    "    Ws = make_views_on_weights(w, shapes)\n",
    "    return w, Ws    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_views_on_weights(w, shapes):    \n",
    "    Ws = []\n",
    "    first = 0\n",
    "    for sh in shapes:\n",
    "        # Create new view of w[first:last]\n",
    "        last = first + sh[0] * sh[1]\n",
    "        # Create new view of w[first:last] as matrix W to be matrix for a layer\n",
    "        W = w[first:last].reshape(sh)\n",
    "        # Initialize weight values to small uniformly-distributed values\n",
    "        n_inputs = sh[0]\n",
    "        scale = 1.0 / np.sqrt(n_inputs)\n",
    "        W[:] = np.random.uniform(-scale, scale, size=sh)\n",
    "        # Add to list of W matrices, Ws.\n",
    "        Ws.append(W)\n",
    "        first = last\n",
    "    return Ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      " [ 0.39675016 -0.3571887   0.69474991 -0.28946352 -0.35505907 -0.0263303\n",
      " -0.03458548 -0.05931803  0.32868892  0.4272183  -0.26720863 -0.56647787\n",
      " -0.54335956  0.00345239  0.48151541 -0.24477155  0.64894793 -0.36087696\n",
      " -0.69324107  0.09934064  0.20000837  0.20301813  0.02072527 -0.09750033\n",
      " -0.295008    0.28621015 -0.14612745 -0.04207432  0.12301131 -0.2567274\n",
      "  0.28496374]\n",
      "V\n",
      " [[ 0.39675016 -0.3571887   0.69474991 -0.28946352 -0.35505907 -0.0263303\n",
      "  -0.03458548 -0.05931803  0.32868892  0.4272183 ]\n",
      " [-0.26720863 -0.56647787 -0.54335956  0.00345239  0.48151541 -0.24477155\n",
      "   0.64894793 -0.36087696 -0.69324107  0.09934064]]\n",
      "W\n",
      " [[ 0.20000837]\n",
      " [ 0.20301813]\n",
      " [ 0.02072527]\n",
      " [-0.09750033]\n",
      " [-0.295008  ]\n",
      " [ 0.28621015]\n",
      " [-0.14612745]\n",
      " [-0.04207432]\n",
      " [ 0.12301131]\n",
      " [-0.2567274 ]\n",
      " [ 0.28496374]]\n"
     ]
    }
   ],
   "source": [
    "# Set parameters of neural network\n",
    "nHiddens = 10\n",
    "nOutputs = 1\n",
    "\n",
    "# Initialize weights to uniformly distributed values between small normally-distributed between -0.1 and 0.1\n",
    "Vshape = (1 +1, nHiddens)\n",
    "Wshape = (nHiddens + 1, nOutputs)\n",
    "w, [V, W] = make_weights([Vshape, Wshape])\n",
    "\n",
    "print('w\\n', w)\n",
    "print('V\\n', V)\n",
    "print('W\\n', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some functions for calculating the output of our network, and for backpropagating the error to get a gradient of error with respect to all weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(Ws, X1):\n",
    "    # Forward pass on training data\n",
    "    V, W = Ws\n",
    "    Z = np.tanh(X1 @ V)\n",
    "    Z1 = np.insert(Z, 0, 1, 1)\n",
    "    Y = Z1 @ W\n",
    "    return Z1, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(w, Ws, X1, Z1, T, error):\n",
    "    V, W = Ws\n",
    "    # Backward pass. \n",
    "    # Calculate the gradient of squared error with respect to all weights in w.\n",
    "    #   Order of in w is all hidden layer weights followed by all output layer weights,\n",
    "    #   so gradient values are ordered this way.\n",
    "    gradient =  np.hstack(((- X1.T @ ( ( error @ W[1:, :].T) * (1 - Z1[:, 1:]**2))).flat,  # for hidden layer\n",
    "                          (- Z1.T @ error).flat))  # for output layer\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these functions, we can now define the stochastic gradient descent, `sgd`, procedure to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_init():\n",
    "    pass\n",
    "\n",
    "def sgd(w, Ws, X1, T, learning_rate):\n",
    "    Z1, Y = forward(Ws, X1)\n",
    "\n",
    "    # Error in output\n",
    "    n_samples = X1.shape[0]\n",
    "    n_outputs = T.shape[1]\n",
    "    \n",
    "    error = (T - Y) / (n_samples + n_outputs)\n",
    "\n",
    "    gradient = backward(w, Ws, X1, Z1, T, error)\n",
    "   \n",
    "    # update values of w, in place. Don't need to return it.\n",
    "    \n",
    "    w -= learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another way to update the weights, the `adam` procedure.  See [this discussion](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) of Adam and other gradient descent methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_trace = 0\n",
    "grad_squared_trace = 0\n",
    "update_step = 0\n",
    "\n",
    "def adam_init():\n",
    "    global grad_trace, grad_squared_trace, update_step\n",
    "\n",
    "    grad_trace = 0\n",
    "    grad_squared_trace = 0\n",
    "    update_step = 0\n",
    "    \n",
    "def adam(w, Ws, X1, T, learning_rate):\n",
    "    global grad_trace, grad_squared_trace, update_step\n",
    "\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    Z1, Y = forward(Ws, X1)\n",
    "\n",
    "    # Error in output\n",
    "    error = T - Y\n",
    "\n",
    "    gradient = backward(w, Ws, X1, Z1, T, error)\n",
    "    \n",
    "    # approximate first and second moment\n",
    "    grad_trace = beta1 * grad_trace + (1 - beta1) * gradient\n",
    "    grad_squared_trace = beta2 * grad_squared_trace + (1 - beta2) * np.square(gradient)\n",
    "    \n",
    "    # bias corrected moment estimates\n",
    "    grad_hat = grad_trace / (1 - beta1 ** (update_step + 1) )\n",
    "    grad_squared_hat = grad_squared_trace / (1 - beta2 ** (update_step + 1) )\n",
    "                \n",
    "    dw = grad_hat / (np.sqrt(grad_squared_hat) + epsilon)\n",
    "    \n",
    "    n_samples = X1.shape[0]\n",
    "    n_outputs = T.shape[1]\n",
    "    \n",
    "    # update values of w, in place. Don't need to return it.\n",
    "    w -= learning_rate / (n_samples + n_outputs) * dw\n",
    "    \n",
    "    update_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, wrap these all together into a function to train a neural network given the training and testing data, the gradient descent function names, the batch size, the number of epochs, the learning rate, and the graphics update rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Xtrain, Ttrain, Xtest, Ttest,\n",
    "          n_hiddens, \n",
    "          gradient_descent_method_init, gradient_descent_method, \n",
    "          batch_size, n_epochs, learning_rate, graphics_rate=0):\n",
    "\n",
    "    if graphics_rate > 0 and Xtrain.shape[1] > 1:\n",
    "        print('Graphics only works when X has one column (data has one input variable)')\n",
    "        print('Setting graphics_rate to 0')\n",
    "        graphics_rate = 0\n",
    "    \n",
    "    # Initialize weights to uniformly distributed values between small normally-distributed between -0.1 and 0.1\n",
    "    n_inputs = Xtrain.shape[1]\n",
    "    n_outputs = Ttrain.shape[1]\n",
    "    Vshape = (1 + n_inputs, n_hiddens)\n",
    "    Wshape = (1 + n_hiddens, n_outputs)\n",
    "    w, [V, W] = make_weights([Vshape, Wshape])\n",
    "\n",
    "    error_trace = np.zeros((n_epochs, 2))\n",
    "\n",
    "    if graphics_rate > 0:\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        \n",
    "    Xtrain1 = np.insert(Xtrain, 0, 1, 1)\n",
    "    Xtest1 = np.insert(Xtest, 0, 1, 1)\n",
    "    n_samples = Xtrain1.shape[0]\n",
    "        \n",
    "    gradient_descent_method_init()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # gradient_descent_method_init()\n",
    "        \n",
    "        # Reorder samples\n",
    "        rows = np.arange(n_samples)\n",
    "        np.random.shuffle(rows)\n",
    "        \n",
    "        for first_n in range(0, n_samples, batch_size):\n",
    "            last_n = first_n + batch_size\n",
    "            rows_batch = rows[first_n:last_n]\n",
    "            Xtrain1_batch = Xtrain1[rows_batch, :]\n",
    "            Ttrain_batch = Ttrain[rows_batch, :]\n",
    "            # gradient_descent method changes values of w\n",
    "            gradient_descent_method(w, [V, W], Xtrain1_batch, Ttrain_batch, learning_rate)\n",
    "    \n",
    "        # error traces for plotting\n",
    "        Z1train, Ytrain = forward([V, W], Xtrain1)\n",
    "        error_trace[epoch, 0] = np.sqrt(np.mean(((Ttrain - Ytrain)**2)))\n",
    "    \n",
    "        Z1test, Ytest = forward([V, W], Xtest1)\n",
    "        error_trace[epoch, 1] = np.sqrt(np.mean((Ytest - Ttest)**2))\n",
    "\n",
    "        if graphics_rate > 0 and (epoch % graphics_rate == 0 or epoch == n_epochs - 1):\n",
    "            plt.clf()\n",
    "            plt.subplot(3, 1, 1)\n",
    "            plt.plot(error_trace[:epoch, :])\n",
    "            plt.ylim(0, 0.4)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend(('Train','Test'), loc='upper left')\n",
    "        \n",
    "            plt.subplot(3, 1, 2)\n",
    "            plt.plot(Xtrain, Ttrain, 'o-', Xtest, Ttest, 'o-', Xtrain, Ytrain, 'o-')\n",
    "            plt.xlim(-1, 1)\n",
    "            plt.ylim(-0.2, 1.6)\n",
    "            plt.legend(('Training', 'Testing', 'Model'), loc='upper left')\n",
    "            plt.xlabel('$x$')\n",
    "            plt.ylabel('Actual and Predicted $f(x)$')\n",
    "        \n",
    "            plt.subplot(3, 1, 3)\n",
    "            plt.plot(Xtrain, Z1train[:, 1:])  # Don't plot the constant 1 column\n",
    "            plt.ylim(-1.1, 1.1)\n",
    "            plt.xlabel('$x$')\n",
    "            plt.ylabel('Hidden Unit Outputs ($z$)');\n",
    "        \n",
    "            ipd.clear_output(wait=True)\n",
    "            ipd.display(fig)\n",
    "\n",
    "    ipd.clear_output(wait=True)\n",
    "\n",
    "    return Ytrain, Ytest, error_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some training data\n",
    "n = 20\n",
    "Xtrain = np.linspace(0.,20.0,n).reshape((n,1)) - 10\n",
    "Ttrain = 0.2 + 0.05 * (Xtrain + 10) + 0.4 * np.sin(Xtrain + 10) + 0.2 * np.sin(Xtrain * 3) + 0.01 * np.random.normal(size=(n, 1))\n",
    "Xtrain = Xtrain / 10\n",
    "\n",
    "# Make some testing data\n",
    "n = n // 3\n",
    "Xtest = np.linspace(0, 20, n).reshape((-1, 1)) - 10\n",
    "Ttest = 0.2 + 0.05 * (Xtest + 10) + 0.2 * np.sin(Xtest + 10) +  0.1 * np.sin(Xtest * 3) + 0.01 * np.random.normal(size=(n, 1))\n",
    "Xtest = Xtest / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE nan\n"
     ]
    }
   ],
   "source": [
    "Ytrain, Ytest, error_trace = train(Xtrain, Ttrain, Xtest, Ttest, n_hiddens=20, \n",
    "                       gradient_descent_method_init=sgd_init, gradient_descent_method=sgd,\n",
    "                       batch_size=Xtrain.shape[0], n_epochs=200000, learning_rate=0.2, graphics_rate=5000)\n",
    "print('Final RMSE', np.sqrt(np.mean((Ttest - Ytest)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain, Ytest, error_trace = train(Xtrain, Ttrain, Xtest, Ttest, n_hiddens=20, \n",
    "                       gradient_descent_method_init=adam_init, gradient_descent_method=adam,\n",
    "                       batch_size=Xtrain.shape[0], n_epochs=100000, learning_rate=0.05, graphics_rate=5000)\n",
    "print('Final RMSE', np.sqrt(np.mean((Ttest - Ytest)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.13628625267906064 Adam 0.13908045168516606\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = Xtrain.shape[0]\n",
    "\n",
    "_, _, error_trace_adam = train(Xtrain, Ttrain, Xtest, Ttest, n_hiddens=20, \n",
    "                       gradient_descent_method_init=adam_init, gradient_descent_method=adam,\n",
    "                       batch_size=n_samples, n_epochs=20000, learning_rate=0.01, graphics_rate=0)\n",
    "\n",
    "_, _, error_trace_sgd = train(Xtrain, Ttrain, Xtest, Ttest, n_hiddens=20, \n",
    "                       gradient_descent_method_init=sgd_init, gradient_descent_method=sgd,\n",
    "                       batch_size=n_samples, n_epochs=20000, learning_rate=0.01, graphics_rate=0)\n",
    "\n",
    "plt.plot(np.hstack((error_trace_sgd[:, 1:], error_trace_adam[:, 1:])))\n",
    "plt.legend(('SGD', 'Adam'))\n",
    "\n",
    "print('SGD', error_trace_sgd[-1, 1], 'Adam', error_trace_adam[-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for Good Parameter Values on a New Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your work begins.  First, download this [Real Estate Valuation Data](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set) from the UCI machine learning repository. Read it in to python and form an input matrix `X` that contains six columns, and target matrix `T` of one column containing the house price of unit area.  This is easiest to do with the [pandas](https://pandas.pydata.org/) package.  Check out the [Getting Started](http://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) material at the pandas site.  Near the bottom of that page are some simple examples of how to use the `read_excel` pandas function.  Pretty handy since the Real Estate data is an `.xlsx` file.  Other helpful functions are the `drop` function that can be used to remove a column, such as the one labeled `No` in the data file, which is just an index that we should ignore, and `data.columns.tolist()` where `data` is a Dataframe.  Also note that a Dataframe can be converted to a `numpy` array by `npdata = np.array(data)` where `data` again is a Dataframe.\n",
    "\n",
    "We want to try to predict the target value from the six input values.\n",
    "\n",
    "Randomly partition the data into an 80% partition for training, making `Xtrain` and `Ttrain`, and a 20% partition for testing, makng `Xtest` and `Ttest`.\n",
    "\n",
    "Standardize the input `Xtrain` and `Xtest` matrices by subtracting by the column means and dividing by the column standard deviations, with the means and standard deviations determined only from the `Xtrain` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data):\n",
    "    data_copy = np.random.permutation(data)\n",
    "    division_index = int(.8*len(data_copy))\n",
    "    training = data_copy[:division_index]\n",
    "    testing = data_copy[division_index:]               \n",
    "    return training, testing\n",
    "\n",
    "def separate_targets(data):\n",
    "    X = data[:, :data.shape[1]-1]\n",
    "    T = data[:,data.shape[1]-1:data.shape[1]]\n",
    "    return X, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data.xlsx', 'Sheet1', index_col=None, na_values=['NA']).drop(\"No\", axis=1)\n",
    "npdata = np.array(data)\n",
    "training, testing = partition(npdata)\n",
    "Xtrain, Ttrain = separate_targets(training)\n",
    "Xtest, Ttest = separate_targets(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the one-hidden layer neural network implemented here, train neural networks in two ways: one with SGD and one with Adam.  For each, try at least three values for each of the following parameters:\n",
    "\n",
    "  * number of hidden units, from 1 to 50,\n",
    "  * batch size,\n",
    "  * number of epochs\n",
    "  * learning_rate\n",
    "\n",
    "Create a table of results containing the algorithm name ('sgd' or 'adam'), the values of the above four parameters, and the RMSE on the training and testing data.  Since this is a mixed-type table, use the `pandas` package.  Sort your table by the test RMSE. \n",
    "\n",
    "Here are some clues on how to do this. To initialize a `pandas` Dataframe, called `results` do\n",
    "\n",
    "      import pandas as pd\n",
    "      \n",
    "      results = pd.DataFrame(columns=['Algorithm', 'Epochs', 'Learning Rate', 'Hidden Units', 'Batch Size', \n",
    "                                'RMSE Train', 'RMSE Test'])\n",
    "To add a row to this, do\n",
    "\n",
    "      results.loc[len(results)] = [algo, n_epochs, lr, nh, bs, rmse(Ytrain, Ttrain), rmse(Ytest, Ttest)]\n",
    "      \n",
    "assuming those variables have appropriate values.  Then, to sort `results` by `RMSE Test` and just see the top 50 entries, do\n",
    "\n",
    "      results.sort_values('RMSE Test').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(Y, T):\n",
    "    return np.sqrt(np.mean((T - Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parameters(Xtrain, Ttrain, Xtest, Ttest, epoch_list, learning_rate_list, hidden_unit_list, batch_size_list, verbose=False):\n",
    "    results = pd.DataFrame(columns=['Algorithm', 'Epochs', 'Learning Rate', 'Hidden Units', 'Batch Size', \n",
    "                            'RMSE Train', 'RMSE Test'])\n",
    "    for algorithm in ['adam', 'sgd']:\n",
    "        init = adam_init if algorithm is 'adam' else sgd_init\n",
    "        method = adam if algorithm is 'adam' else sgd\n",
    "        for epoch in epoch_list:\n",
    "            for learning_rate in learning_rate_list:\n",
    "                for hidden_units in hidden_unit_list:\n",
    "                    for batch_size in batch_size_list:\n",
    "                        Ytrain, Ytest, error_trace = train(Xtrain, Ttrain, Xtest, Ttest, n_hiddens=20, \n",
    "                                               gradient_descent_method_init=init, gradient_descent_method=method,\n",
    "                                               batch_size=batch_size, n_epochs=epoch, learning_rate=learning_rate, graphics_rate=0)\n",
    "                        results.loc[len(results)] = [algorithm, epoch, learning_rate, hidden_units, batch_size, rmse(Ytrain, Ttrain), rmse(Ytest, Ttest)]\n",
    "                    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('machine.data', delimiter=',', usecols=range(2, 10))\n",
    "X = data[:, :-2]\n",
    "T = data[:, -2:-1]\n",
    "Xtrain = X[:160, :]\n",
    "Ttrain = T[:160, :]\n",
    "Xtest = X[160:, :]\n",
    "Ttest = T[160:, :]\n",
    "\n",
    "means = Xtrain.mean(0)\n",
    "stds = Xtrain.std(0)\n",
    "Xtrains = (Xtrain - means) / stds\n",
    "Xtests = (Xtest - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the above steps into a new function named `run_parameters` that accepts the arguments\n",
    "\n",
    "    * Xtrain, standardized\n",
    "    * Ttrain\n",
    "    * Xtest, standardized\n",
    "    * Ttest\n",
    "    * list of numbers of epochs\n",
    "    * list of learning rates\n",
    "    * list of numbers of hidden units\n",
    "    * list of batch sizes\n",
    "    * verbose, if True then print results of each parameter value combination\n",
    "\n",
    "and returns a pandas DataFrame containing the results of runs for all combinations of the above parameter values. The DataFrame must have columns titled `[Algorithm', 'Epochs', 'Learning Rate', 'Hidden Units', 'Batch Size', 'RMSE Train', 'RMSE Test']`.  So, if eac of the above lists contains two values, the resulting DataFrame must have 16 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your experiments, including how you decided on what values to test, and what the results tell you.  \n",
    "\n",
    "Extract the `RMSE test` values for all values of `Hidden Units` using the best values for the other parameters.  Here is an example of how to do this.\n",
    "\n",
    "    nh =results.loc[(results['Algorithm'] == 'adam') & (results['Epochs'] == 100) &\n",
    "                    (results['Learning Rate'] == 0.002) & (results['Batch Size'] == 1)]\n",
    "                    \n",
    "Now you can plot the training and testing RMSE versus the hidden units.  Describe what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_parameters(Xtrains, Ttrain, Xtests, Ttest, [100, 1000, 5000], [0.01, 0.05, .1], [1, 25, 50], [25, 50, 75], verbose=False)\n",
    "nh = results.loc[(results['Algorithm'] == 'adam') & (results['Epochs'] == 100) &\n",
    "                (results['Learning Rate'] == 0.001) & (results['Batch Size'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the following values in my test run.\n",
    "\n",
    "epochs: 100, 500, 1000\n",
    "\n",
    "learning rates: .01, .05, .1 \n",
    "\n",
    "hidden units: 1, 25, 50\n",
    "\n",
    "batch sizes: 25, 50, 75\n",
    "\n",
    "My intention has been to gather data for a great range of potential values for each input, though my epoch counts are admittedly low (this is from a practical standpoint).\n",
    "\n",
    "Below are the ten best RMSE Test values from this run, showing 'sgd' as the prevailing algorithm in this context. There are also plots showing the RMSE Train (orange) and Test (green) values in comparison to the number of hidden units (blue) in a test with 1000 epochs, a batch size of 25, and a learning rate controlled values. I've included one for the sgd algorithm (top) and one for the adam algorithm (bottom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Hidden Units</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>sgd</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>63.993655</td>\n",
       "      <td>71.832304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>sgd</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>54.540165</td>\n",
       "      <td>97.332165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>sgd</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>58.821608</td>\n",
       "      <td>106.733553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sgd</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>62.889458</td>\n",
       "      <td>113.785541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sgd</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>73.160386</td>\n",
       "      <td>130.998412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>sgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>75.256448</td>\n",
       "      <td>136.827544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>75</td>\n",
       "      <td>72.019764</td>\n",
       "      <td>138.369906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>sgd</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>76.171356</td>\n",
       "      <td>140.245510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>sgd</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>68.443108</td>\n",
       "      <td>141.035347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>72.866244</td>\n",
       "      <td>146.184433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm Epochs  Learning Rate Hidden Units Batch Size  RMSE Train  \\\n",
       "147       sgd   5000           0.05           25         25   63.993655   \n",
       "145       sgd   5000           0.05            1         50   54.540165   \n",
       "153       sgd   5000           0.10            1         25   58.821608   \n",
       "128       sgd   1000           0.10            1         75   62.889458   \n",
       "149       sgd   5000           0.05           25         75   73.160386   \n",
       "91        sgd    100           0.05            1         50   75.256448   \n",
       "89        sgd    100           0.01           50         75   72.019764   \n",
       "138       sgd   5000           0.01           25         25   76.171356   \n",
       "110       sgd   1000           0.01            1         75   68.443108   \n",
       "86        sgd    100           0.01           25         75   72.866244   \n",
       "\n",
       "      RMSE Test  \n",
       "147   71.832304  \n",
       "145   97.332165  \n",
       "153  106.733553  \n",
       "128  113.785541  \n",
       "149  130.998412  \n",
       "91   136.827544  \n",
       "89   138.369906  \n",
       "138  140.245510  \n",
       "110  141.035347  \n",
       "86   146.184433  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd_nh = results.loc[(results['Algorithm'] == 'sgd') & (results['Epochs'] == 100) &\n",
    "                (results['Learning Rate'] == 0.05) & (results['Batch Size'] == 25)].drop(\"Epochs\", axis=1).drop(\"Batch Size\", axis=1).drop(\"Learning Rate\", axis=1)\n",
    "\n",
    "adam_nh = results.loc[(results['Algorithm'] == 'adam') & (results['Epochs'] == 100) &\n",
    "                (results['Learning Rate'] == 0.05) & (results['Batch Size'] == 25)].drop(\"Epochs\", axis=1).drop(\"Batch Size\", axis=1).drop(\"Learning Rate\", axis=1)\n",
    "\n",
    "sgd_nh.plot(title=\"SGD\")\n",
    "\n",
    "adam_nh.plot(title=\"ADAM\")\n",
    "\n",
    "results.sort_values('RMSE Test').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above shows sgd to have more accurate results, and that those results are more accurate at the midpoint of possible hidden units values (25). This reflects what I know about the adam optimization algorithm, showing that using fewer epochs, sgd can be as effective or moreso (as seen here) than the optimization, which allows more effective training relative to the number of epochs, unlike sgd which flattens out at an earlier point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [A2grader.tar](http://www.cs.colostate.edu/~anderson/cs445/notebooks/A2grader.tar) and extract `A2grader.py` from it. Run the code in the following cell to demonstrate an example grading session.  You should see a perfect execution score of 90 out of 90 points if your functions are defined correctly. The remaining 10 points will be based on the results you obtain from the energy data and on your discussions.\n",
    "\n",
    "For the grading script to run correctly, you must first name this notebook as 'Lastname-A2.ipynb' with 'Lastname' being your last name, and then save this notebook.\n",
    "\n",
    "A different, but similar, grading script will be used to grade your checked-in notebook.  It will include additional tests.  You need not include code to test that the values passed in to your functions are the correct form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Algorithm Epochs  Learning Rate Hidden Units Batch Size  RMSE Train  \\\n",
      "0       adam     10          0.001            5          1  168.967265   \n",
      "1       adam     10          0.001            5         50  172.501939   \n",
      "2       adam     10          0.001           10          1  169.048043   \n",
      "3       adam     10          0.001           10         50  172.682357   \n",
      "4       adam     10          0.010            5          1  141.247677   \n",
      "5       adam     10          0.010            5         50  172.689262   \n",
      "6       adam     10          0.010           10          1  140.833241   \n",
      "7       adam     10          0.010           10         50  172.667873   \n",
      "8       adam    100          0.001            5          1  141.067645   \n",
      "9       adam    100          0.001            5         50  172.605579   \n",
      "10      adam    100          0.001           10          1  140.985064   \n",
      "11      adam    100          0.001           10         50  172.467506   \n",
      "12      adam    100          0.010            5          1   72.842752   \n",
      "13      adam    100          0.010            5         50  171.325213   \n",
      "14      adam    100          0.010           10          1   72.656818   \n",
      "15      adam    100          0.010           10         50  171.612907   \n",
      "16       sgd     10          0.001            5          1   77.218358   \n",
      "17       sgd     10          0.001            5         50  149.307192   \n",
      "18       sgd     10          0.001           10          1   86.713141   \n",
      "19       sgd     10          0.001           10         50  151.766255   \n",
      "20       sgd     10          0.010            5          1  107.810627   \n",
      "21       sgd     10          0.010            5         50   95.218795   \n",
      "22       sgd     10          0.010           10          1   84.388859   \n",
      "23       sgd     10          0.010           10         50   97.108064   \n",
      "24       sgd    100          0.001            5          1   59.620097   \n",
      "25       sgd    100          0.001            5         50   91.738480   \n",
      "26       sgd    100          0.001           10          1   65.554629   \n",
      "27       sgd    100          0.001           10         50   92.268268   \n",
      "28       sgd    100          0.010            5          1   79.203293   \n",
      "29       sgd    100          0.010            5         50   67.599260   \n",
      "30       sgd    100          0.010           10          1   81.790398   \n",
      "31       sgd    100          0.010           10         50   61.381254   \n",
      "\n",
      "     RMSE Test  \n",
      "0   241.449344  \n",
      "1   244.778509  \n",
      "2   241.563670  \n",
      "3   245.164266  \n",
      "4   215.473207  \n",
      "5   245.153845  \n",
      "6   215.074977  \n",
      "7   244.992925  \n",
      "8   215.312903  \n",
      "9   244.946686  \n",
      "10  215.226428  \n",
      "11  244.821860  \n",
      "12  185.147091  \n",
      "13  243.843640  \n",
      "14  177.933052  \n",
      "15  243.941395  \n",
      "16  155.869854  \n",
      "17  222.909183  \n",
      "18  172.339036  \n",
      "19  225.301876  \n",
      "20  173.598300  \n",
      "21  178.701682  \n",
      "22  158.601137  \n",
      "23  183.388506  \n",
      "24  200.214505  \n",
      "25  186.291664  \n",
      "26  143.190853  \n",
      "27  188.643640  \n",
      "28  190.759275  \n",
      "29  180.157444  \n",
      "30  181.572731  \n",
      "31  180.585059  \n",
      "\n",
      "\n",
      "--- 40/40 points. run_parameters terminates.\n",
      "\n",
      "--- 20/20 points. results.shape is correct.\n",
      "\n",
      "--- 10/10 points. results column names is correct.\n",
      "\n",
      "--- 10/10 points. Values in results Algorithm column correct.\n",
      "\n",
      "--- 10/10 points. Number of epochs for lowest RMSE Train is correct.\n",
      "\n",
      "C:\\Users\\allth\\Desktop\\CS445\\A2 Execution Grade is 90 / 90\n",
      "\n",
      " Remaining 10 points will be based on your text descriptions of results and plots.\n",
      "\n",
      "C:\\Users\\allth\\Desktop\\CS445\\A2 FINAL GRADE is   / 100\n",
      "\n",
      "C:\\Users\\allth\\Desktop\\CS445\\A2 EXTRA CREDIT is   / 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i A2grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "\n",
    "Repeat the evaluation of parameter values for another data set of your choice."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
